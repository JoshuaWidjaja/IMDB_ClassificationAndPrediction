{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "CS175 Final Turn-In",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sbYsEDSs6LEa"
      },
      "source": [
        "# This Google Colab is a simplified version of the original code. It instead imports already trained models and created data to provide a very quick simulation of what our models do and what they are capable of."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TVNUBWzK6HDo"
      },
      "source": [
        "# Section 0: Setup and Importing Libraries\r\n",
        "\r\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0UzBy0r9mbZ-",
        "outputId": "b7a355a0-3e71-45d2-85b4-6b27e9c0b35f"
      },
      "source": [
        "#This entire script is meant to be run in Google Colab\r\n",
        "\r\n",
        "#We clone the github to easily grab the dataset information without having to manually import it to Google Colab each time. Additionally, we install necessary libraries here.\r\n",
        "#Libraries are: Pytorch, NLTK, and Gensim.\r\n",
        "!git clone https://github.com/JoshuaWidjaja/IMDB_ClassificationAndPrediction\r\n",
        "!pip install torch===1.8.1 torchvision===0.8.2 torchaudio===0.7.2 -f https://download.pytorch.org/whl/torch_stable.html\r\n",
        "!pip install --user -U nltk\r\n",
        "!pip install gensim\r\n",
        "\r\n",
        "#Imports, generally we isolate each import to it's proper block to easier read/organize the code.\r\n",
        "#For the purpose of this shorter demonstration file, we import everything at the top.\r\n",
        "import os\r\n",
        "import math\r\n",
        "import sklearn\r\n",
        "import torch.nn as nn\r\n",
        "import torch as torch\r\n",
        "import numpy as np\r\n",
        "import torch.nn\r\n",
        "import torch.nn.functional\r\n",
        "\r\n",
        "from joblib import dump, load\r\n",
        "from sklearn import linear_model\r\n",
        "from sklearn import tree\r\n",
        "from sklearn import ensemble\r\n",
        "from sklearn import neighbors\r\n",
        "from sklearn import linear_model \r\n",
        "from sklearn import metrics \r\n",
        "from torch.utils.data import DataLoader, TensorDataset\r\n",
        "from sklearn.feature_extraction.text import * \r\n",
        "from sklearn.model_selection import train_test_split \r\n",
        "\r\n",
        "\r\n",
        "\r\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Cloning into 'IMDB_ClassificationAndPrediction'...\n",
            "remote: Enumerating objects: 41, done.\u001b[K\n",
            "remote: Counting objects: 100% (41/41), done.\u001b[K\n",
            "remote: Compressing objects: 100% (35/35), done.\u001b[K\n",
            "remote: Total 98548 (delta 9), reused 28 (delta 5), pack-reused 98507\u001b[K\n",
            "Receiving objects: 100% (98548/98548), 121.25 MiB | 18.37 MiB/s, done.\n",
            "Resolving deltas: 100% (16/16), done.\n",
            "Checking out files: 100% (100030/100030), done.\n",
            "Looking in links: https://download.pytorch.org/whl/torch_stable.html\n",
            "\u001b[31mERROR: Could not find a version that satisfies the requirement torch===1.8.1 (from versions: 0.1.2, 0.1.2.post1, 0.1.2.post2, 0.4.1, 0.4.1.post2, 1.0.0, 1.0.1, 1.0.1.post2, 1.1.0, 1.2.0, 1.2.0+cpu, 1.2.0+cu92, 1.3.0, 1.3.0+cpu, 1.3.0+cu100, 1.3.0+cu92, 1.3.1, 1.3.1+cpu, 1.3.1+cu100, 1.3.1+cu92, 1.4.0, 1.4.0+cpu, 1.4.0+cu100, 1.4.0+cu92, 1.5.0, 1.5.0+cpu, 1.5.0+cu101, 1.5.0+cu92, 1.5.1, 1.5.1+cpu, 1.5.1+cu101, 1.5.1+cu92, 1.6.0, 1.6.0+cpu, 1.6.0+cu101, 1.6.0+cu92, 1.7.0, 1.7.0+cpu, 1.7.0+cu101, 1.7.0+cu110, 1.7.0+cu92, 1.7.1, 1.7.1+cpu, 1.7.1+cu101, 1.7.1+cu110, 1.7.1+cu92, 1.7.1+rocm3.7, 1.7.1+rocm3.8, 1.8.0, 1.8.0+cpu, 1.8.0+cu101, 1.8.0+cu111, 1.8.0+rocm3.10, 1.8.0+rocm4.0.1)\u001b[0m\n",
            "\u001b[31mERROR: No matching distribution found for torch===1.8.1\u001b[0m\n",
            "Collecting nltk\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/92/75/ce35194d8e3022203cca0d2f896dbb88689f9b3fce8e9f9cff942913519d/nltk-3.5.zip (1.4MB)\n",
            "\u001b[K     |████████████████████████████████| 1.4MB 4.4MB/s \n",
            "\u001b[?25hRequirement already satisfied, skipping upgrade: click in /usr/local/lib/python3.7/dist-packages (from nltk) (7.1.2)\n",
            "Requirement already satisfied, skipping upgrade: joblib in /usr/local/lib/python3.7/dist-packages (from nltk) (1.0.1)\n",
            "Requirement already satisfied, skipping upgrade: regex in /usr/local/lib/python3.7/dist-packages (from nltk) (2019.12.20)\n",
            "Requirement already satisfied, skipping upgrade: tqdm in /usr/local/lib/python3.7/dist-packages (from nltk) (4.41.1)\n",
            "Building wheels for collected packages: nltk\n",
            "  Building wheel for nltk (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for nltk: filename=nltk-3.5-cp37-none-any.whl size=1434678 sha256=aad2dacdafb91f3e385475290bdc62360ef4dee25d3276c57042b081d93f7d62\n",
            "  Stored in directory: /root/.cache/pip/wheels/ae/8c/3f/b1fe0ba04555b08b57ab52ab7f86023639a526d8bc8d384306\n",
            "Successfully built nltk\n",
            "Installing collected packages: nltk\n",
            "\u001b[33m  WARNING: The script nltk is installed in '/root/.local/bin' which is not on PATH.\n",
            "  Consider adding this directory to PATH or, if you prefer to suppress this warning, use --no-warn-script-location.\u001b[0m\n",
            "Successfully installed nltk-3.5\n",
            "Requirement already satisfied: gensim in /usr/local/lib/python3.7/dist-packages (3.6.0)\n",
            "Requirement already satisfied: smart-open>=1.2.1 in /usr/local/lib/python3.7/dist-packages (from gensim) (4.2.0)\n",
            "Requirement already satisfied: six>=1.5.0 in /usr/local/lib/python3.7/dist-packages (from gensim) (1.15.0)\n",
            "Requirement already satisfied: scipy>=0.18.1 in /usr/local/lib/python3.7/dist-packages (from gensim) (1.4.1)\n",
            "Requirement already satisfied: numpy>=1.11.3 in /usr/local/lib/python3.7/dist-packages (from gensim) (1.19.5)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "60VatNg9xLLe"
      },
      "source": [
        "# Section 1: Positive and Negative Classifiers\r\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GlPGAlGinuTq",
        "outputId": "d4b854da-7f4c-4f3d-e9cc-e04c862bae3f"
      },
      "source": [
        "#Loading in the data and the model from the Google Colab directory.\r\n",
        "#This block handles our logistic classifier and classifiers either as Positive or Negative.\r\n",
        "dataFile = np.load(os.getcwd() + \"/IMDB_ClassificationAndPrediction/Demonstration_Files/demonstrationData.npz\")\r\n",
        "logisticClassifier = load(os.getcwd() + \"/IMDB_ClassificationAndPrediction/Demonstration_Files/classification_LogisticClassifier.joblib\")\r\n",
        "\r\n",
        "#This is the format that the dataFile takes due to exporting as an npz file: ['arr_0', 'arr_1', 'arr_2', 'arr_3', 'arr_4', 'arr_5', 'arr_6']\r\n",
        "\r\n",
        "#Assigning features here.\r\n",
        "ratingFeature = dataFile[\"arr_0\"]\r\n",
        "withStopWordsFeature = dataFile[\"arr_1\"]\r\n",
        "removeStopWordsFeature =dataFile[\"arr_2\"]\r\n",
        "reviewLengthFeature = dataFile[\"arr_3\"]\r\n",
        "uniqueWordsFeature = dataFile[\"arr_4\"]\r\n",
        "sentimentRatingFeature = dataFile[\"arr_5\"]\r\n",
        "sentimentRatingFeatureWithNeutral = dataFile[\"arr_6\"]\r\n",
        "\r\n",
        "#We split the data here into 50/50. In these examples, we are using the testing data from our dataset to obtain results. \r\n",
        "#The model has already been trained on our training data, however we decided to demonstrate our model working using similar methods as\r\n",
        "#our original Colab.\r\n",
        "dataSplitFrac = .5\r\n",
        "trainX, validX, trainY, validY = train_test_split(removeStopWordsFeature, sentimentRatingFeature, train_size = dataSplitFrac, random_state = 15)\r\n",
        "trainX = trainX.reshape(-1,1)\r\n",
        "validX = validX.reshape(-1,1)\r\n",
        "\r\n",
        "#fitLogisticClassifier = logisticClassifier.fit(trainX, trainY)\r\n",
        "print(\"Logistic - Without Neutral\")\r\n",
        "#Calculate the accuracy of the first 50% of the data.\r\n",
        "fitLogisticClassifier = logisticClassifier\r\n",
        "trainingPredictions = fitLogisticClassifier.predict(trainX)\r\n",
        "trainingAccuracy =  fitLogisticClassifier.score(trainX, trainY)\r\n",
        "print('Accuracy of first 50%:',format( 100*trainingAccuracy , '.2f') ) \r\n",
        "\r\n",
        "#Calculate the accuracy of the remaining 50% of the data\r\n",
        "testPredictions = fitLogisticClassifier.predict(validX)\t \r\n",
        "testAccuracy = fitLogisticClassifier.score(validX,validY)\r\n",
        "print('Accuracy of last 50%:', format( 100*testAccuracy , '.2f') )"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Logistic - Without Neutral\n",
            "Accuracy of first 50%: 85.20\n",
            "Accuracy of last 50%: 84.70\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GDKFumzSyFfH",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "061639df-b41f-4395-fa0f-6df98ab2a88d"
      },
      "source": [
        "#Loading in the data and the model from the Google Colab directory.\r\n",
        "#This block handles our KNN Classifier and classifiers as either Positive or Negative.\r\n",
        "knn = load(os.getcwd() + \"/IMDB_ClassificationAndPrediction/Demonstration_Files/classification_KNN.joblib\")\r\n",
        "\r\n",
        "#Demonstrating with the KNN model and calculating the accuracy of the first 50% of the data.\r\n",
        "print(\"KNN - Without Neutral\")\r\n",
        "fitknn = knn.fit(trainX, trainY)\r\n",
        "trainingPredictions = fitknn.predict(trainX)\r\n",
        "trainingAccuracy =  fitknn.score(trainX, trainY)\r\n",
        "print('Accuracy of first 50%:',format( 100*trainingAccuracy , '.2f') ) \r\n",
        "\r\n",
        "#Calculate the accuracy of the remaining 50% of the data\r\n",
        "testPredictions = fitknn.predict(validX)\t \r\n",
        "testAccuracy = fitknn.score(validX,validY)\r\n",
        "print('Accuracy of last 50%:',format( 100*testAccuracy , '.2f') ) "
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "KNN - Without Neutral\n",
            "Accuracy of first 50%: 85.29\n",
            "Accuracy of last 50%: 84.70\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0oho66EFNYT1"
      },
      "source": [
        "# Section 2: Positive, Negative, and Neutral Classifiers\r\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Iomo8UqN9FiP",
        "outputId": "2b0116df-ec9e-4d6e-9fbe-5d2c0bc74a9a"
      },
      "source": [
        "#Loading in the data and the model from the Google Colab directory.\r\n",
        "#This block handles our KNN Classifier and classifiers as either Positive, Negative, or Neutral.\r\n",
        "knnMulti = load(os.getcwd() + \"/IMDB_ClassificationAndPrediction/Demonstration_Files/classification_KNN_Neutral.joblib\")\r\n",
        "\r\n",
        "#Setting up variables.\r\n",
        "neutraltrainX, neutralvalidX, neutraltrainY, neutralvalidY = train_test_split(withStopWordsFeature,sentimentRatingFeatureWithNeutral, train_size = dataSplitFrac, random_state = 15)\r\n",
        "neutraltrainX = neutraltrainX.reshape(-1,1)\r\n",
        "neutralvalidX = neutralvalidX.reshape(-1,1)\r\n",
        "\r\n",
        "print(\"KNN - With Neutral\")\r\n",
        "#Demonstrating with the KNN model and calculating the accuracy of the first 50% of the data.\r\n",
        "fitknnMulti = knnMulti.fit(neutraltrainX, neutraltrainY)\r\n",
        "trainingPredictions = knnMulti.predict(neutraltrainX)\r\n",
        "trainingAccuracy =  knnMulti.score(neutraltrainX, neutraltrainY)\r\n",
        "print('Accuracy of first 50%:',format( 100*trainingAccuracy , '.2f') ) \r\n",
        "\r\n",
        "#Calculate the remaining 50% of the data\r\n",
        "testPredictions = knnMulti.predict(neutralvalidX)\t \r\n",
        "testAccuracy = knnMulti.score(neutralvalidX,neutralvalidY)\r\n",
        "print('Accuracy of last 50%:', format( 100*testAccuracy , '.2f') )\r\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "KNN - With Neutral\n",
            "Accuracy of first 50%: 70.62\n",
            "Accuracy of last 50%: 69.33\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lhcm41eONgIQ"
      },
      "source": [
        "# Section 3: WordToVec Implementation"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DXUR_YiJ6BBr"
      },
      "source": [
        "#Loading in the data and model required for our WordToVec Implementation.\r\n",
        "#The following two blocks show an example of one of our classifiers trained using the Word2Vec features instead of our other features.\r\n",
        "#The example here is a logistic classifier trained using WordToVec features and with classification of positive or negative.\r\n",
        "word2VecData = np.load(os.getcwd() + \"/IMDB_ClassificationAndPrediction/Demonstration_Files/wordToVecDemonstration.npz\")\r\n",
        "wordToVecLogisticClassifier = load(os.getcwd() + \"/IMDB_ClassificationAndPrediction/Demonstration_Files/classification_wordToVecLogistic.joblib\")\r\n",
        "\r\n",
        "#This is the format that the dataFile takes due to exporting as an npz file:  ['arr_0', 'arr_1', 'arr_2']\r\n",
        "\r\n",
        "#Assigning features\r\n",
        "tensorVectors = word2VecData[\"arr_0\"]\r\n",
        "ratingListArray = word2VecData[\"arr_1\"]\r\n",
        "ratingListArrayNeutral = word2VecData[\"arr_2\"]\r\n",
        "VectrainX, VecvalidX, VectrainY, VecvalidY = train_test_split(tensorVectors, ratingListArray,\r\n",
        "                                                  train_size = dataSplitFrac, random_state = 15)\r\n",
        "VectrainXNeutral, VecvalidXNeutral, VectrainYNeutral, VecvalidYNeutral = train_test_split(tensorVectors, ratingListArrayNeutral,\r\n",
        "                                                                          train_size = dataSplitFrac, random_state = 15)\r\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LEt6S_WN7gup",
        "outputId": "dea16480-d99c-4652-d9fa-c686de13db9c"
      },
      "source": [
        "#Calculating the first 50% of the data\r\n",
        "print(\"WordToVec Logistic - Without Neutral\")\r\n",
        "fitword2vecLog = wordToVecLogisticClassifier.fit(VectrainX, VectrainY)\r\n",
        "trainingPredictions = fitword2vecLog.predict(VectrainX)\r\n",
        "trainingAccuracy =  fitword2vecLog.score(VectrainX, VectrainY)\r\n",
        "print('Accuracy of first 50%:',format( 100*trainingAccuracy , '.2f') ) \r\n",
        "\r\n",
        "#Calculating the remaining 50%\r\n",
        "testPredictions = fitword2vecLog.predict(VecvalidX)\t \r\n",
        "testAccuracy = fitword2vecLog.score(VecvalidX,VecvalidY)\r\n",
        "\r\n",
        "print('Accuracy of last 50%: accuracy:', format( 100*testAccuracy , '.2f') )"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WordToVec Logistic - Without Neutral\n",
            "Accuracy of first 50%: 57.21\n",
            "Accuracy of last 50%: accuracy: 56.76\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Oi8ZJezcxO8a"
      },
      "source": [
        "#Section 4: Prediction Model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mZehbc1Yua2f",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ad990392-e58c-4927-9e9f-58aaa074898e"
      },
      "source": [
        "#This block is a demonstration of our prediction model, copied directly from the original Google Colab.\r\n",
        "\r\n",
        "#Required class for our prediction model\r\n",
        "class LinReg(nn.Module):\r\n",
        "  def __init__(self):\r\n",
        "    super(LinReg, self).__init__()\r\n",
        "    self.hid = nn.Linear(1, 3)\r\n",
        "    self.lin = nn.Linear(3, 1)\r\n",
        "\r\n",
        "  def forward(self, w):\r\n",
        "    output = torch.nn.functional.relu(self.hid(w))\r\n",
        "    output = self.lin(output)\r\n",
        "    return output\r\n",
        "\r\n",
        "\r\n",
        "#Assigning features\r\n",
        "testX = removeStopWordsFeature\r\n",
        "testY = ratingFeature\r\n",
        "\r\n",
        "#Grab total review weights for the test dataset and their associated review scores\r\n",
        "test_input = torch.unsqueeze(torch.FloatTensor(testX), 1)\r\n",
        "test_labels = torch.unsqueeze(torch.FloatTensor(testY), 1)\r\n",
        "\r\n",
        "#Load model\r\n",
        "score_prediction_model = torch.load(os.getcwd() + \"/IMDB_ClassificationAndPrediction/Demonstration_Files/score_prediction.pt\")\r\n",
        "score_prediction_model.eval()\r\n",
        "\r\n",
        "#Test score prediction\r\n",
        "predicted_test_output = score_prediction_model(test_input)\r\n",
        "normalized_mse = float(torch.nn.MSELoss()(predicted_test_output, test_labels)) / ((10.0 - 1.0) ** 2.0)\r\n",
        "\r\n",
        "print(\"Normalized test MSE: \", normalized_mse)\r\n",
        "\r\n",
        "#Test classification\r\n",
        "correct = 0.0\r\n",
        "incorrect = 0.0\r\n",
        "\r\n",
        "for i, e in enumerate(test_input):\r\n",
        "  model_output = float(score_prediction_model(test_input[i])[0])\r\n",
        "  actual_score = float(test_labels[i][0])\r\n",
        "  if (model_output >= 5.5 and actual_score >= 5.5):\r\n",
        "    correct += 1.0\r\n",
        "  elif (model_output < 5.5 and actual_score < 5.5):\r\n",
        "    correct += 1.0\r\n",
        "  else:\r\n",
        "    incorrect += 1.0\r\n",
        "\r\n",
        "print(\"Classification (positive/negative) test accuracy: \", ((correct / (correct + incorrect)) * 100.0), \"%\")\r\n",
        "print(\"This model was trained on a three-layer feedforward neural network with linear regression over 30,000 epochs. It uses one feature (aggregate review weight).\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Normalized test MSE:  0.06518174395149137\n",
            "Classification (positive/negative) test accuracy:  84.944 %\n",
            "This model was trained on a three-layer feedforward neural network with linear regression over 30,000 epochs. It uses one feature (aggregate review weight).\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}